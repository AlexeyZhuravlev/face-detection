{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "\n",
    "Hello! In this task you will create your own deep face detector.\n",
    "\n",
    "First of all, we need import some usefull stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_data import load_dataset, unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load dataset.\n",
    "\n",
    "Each image in train, validation and test datasets have shape (176, 176, 3), but part of this image is black background. Interesting image aligned at top left corner.\n",
    "\n",
    "Bounding boxes define face in image and consist of 7 integer numbers: [image_index, min_row, min_col, max_row, max_col]. Bounding box width and height are 32 +/- 8 pixels wide.\n",
    "\n",
    "`train_bboxes` and `val_bboxes` is a list of bboxes.\n",
    "\n",
    "`train_shapes` and `val_shapes` is a list of interesting image shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images, train_bboxes, train_shapes = load_dataset(\"train\")\n",
    "val_images, val_bboxes, val_shapes = load_dataset(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "For learning we should extract positive and negative samples from image.\n",
    "Positive and negative samples counts should be similar.\n",
    "Every samples should have same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_SHAPE = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scores import iou_score\n",
    "\n",
    "def is_new_bbox(new_bbox, true_bboxes, eps=1e-1):\n",
    "    \"\"\"There bbox is 4 ints [min_row, min_col, max_row, max_col] without image index.\"\"\"\n",
    "    for bbox in true_bboxes:\n",
    "        if iou_score(new_bbox, bbox) >= eps:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_positive_negative(images, true_bboxes, image_shapes):\n",
    "    \"\"\"Retrieve positive and negative samples from image.\"\"\"\n",
    "    positive = []\n",
    "    negative = []\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_samples(images, true_bboxes, image_shapes):\n",
    "    \"\"\"Usefull samples for learning.\n",
    "\n",
    "    X - positive and negative samples.\n",
    "    Y - one hot encoded list of zeros and ones. One is positive marker.\n",
    "    \"\"\"\n",
    "    positive, negative = get_positive_negative(images=images, true_bboxes=true_bboxes, image_shapes=image_shapes)\n",
    "    X = positive\n",
    "    y = [1] * len(positive)\n",
    "\n",
    "    X.extend(negative)\n",
    "    y.extend([0] * len(negative))\n",
    "\n",
    "    return np.array(X), to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_samples(data, n_cols=5, n_rows=1):\n",
    "    \"\"\"Visualize samples.\"\"\"\n",
    "    figure(figsize = (3*n_cols,3*n_rows))\n",
    "    for n,i in enumerate(np.random.randint(len(data), size = n_cols*n_rows)):\n",
    "        plt.subplot(n_rows,n_cols,n+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = get_samples(train_images, train_bboxes, train_shapes)\n",
    "X_val, Y_val = get_samples(val_images, val_bboxes, val_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There we should see faces\n",
    "visualize_samples(X_train[Y_train[:, 1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There we shouldn't see faces\n",
    "visualize_samples(X_train[Y_train[:, 1] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificator training\n",
    "\n",
    "First of all, we should train face classifier that checks if face represented on sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator # Usefull thing. Read the doc.\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "# Very usefull, pay attention\n",
    "\n",
    "def fit(model_name, model, datagen, X_train, Y_train, X_val, Y_val, class_weight=None, epochs=10, lr=0.001, verbose=False):\n",
    "    \"\"\"Fit model.\n",
    "\n",
    "    You can edit this function anyhow.\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    model.compile(optimizer=RMSprop(lr=lr), # You can use another optimizer\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
    "                                  validation_data=(datagen.standardize(X_val), Y_val),\n",
    "                                  epochs=epochs, steps_per_epoch=len(X_train) / BATCH_SIZE,\n",
    "                                  callbacks=[ModelCheckpoint(\"data/checkpoints/{model_name}\".format(model_name=model_name) + \"-{epoch:02d}-{val_loss:.2f}.hdf5\", save_best_only=True),\n",
    "                                             #\n",
    "                                             # EarlyStopping(patience=20),\n",
    "                                             # ReduceLROnPlateau(patience=10)\n",
    "                                            ],\n",
    "                                  class_weight=class_weight,\n",
    "\n",
    "                                 )  # starts training\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Input, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "# Classification model\n",
    "# For start you can try LeNet architecture\n",
    "\n",
    "x = inputs = Input(shape=SAMPLE_SHAPE)\n",
    "\n",
    "# Write code there\n",
    "\n",
    "# This creates a model\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "fit(model_name=\"MODEL_NAME\", model=model, datagen=datagen, X_train=X_train, X_val=X_val, Y_train=Y_train, Y_val=Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning model weights saves in folder `data/checkpoints/`.\n",
    "Use `model.load_weights(fname)` to load best weights from learning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weight(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection\n",
    "\n",
    "If you have selected classification architecture with high validation score, you can use this architecture for detection.\n",
    "\n",
    "Convert classification architecture to fully convolutional neural network (FCNN), that returns heatmap of activation.\n",
    "\n",
    "You should replace fully-connected layers with convolutional layers. Then you need write function that replace fcnn weights with base model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FCNN\n",
    "\n",
    "IMAGE_SHAPE = (176, 176, 3)\n",
    "\n",
    "def generate_fcnn_model(image_shape):\n",
    "    \"\"\"After model compilation image size fixes.\n",
    "\n",
    "    So, we need create a function to change size later.\n",
    "    \"\"\"\n",
    "    x = inputs = Input(shape=image_shape)\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    # This creates a model\n",
    "    predictions = Conv2D(1, (1, 1), activation='relu')(x)\n",
    "    return Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "fcnn_model = generate_fcnn_model(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_weights(base_model, fcnn_model):\n",
    "    \"\"\"Set FCNN weights from base model.\n",
    "    \"\"\"\n",
    "\n",
    "    fcnn_weights = []\n",
    "    prev_fcnn_weights = fcnn_model.get_weights()\n",
    "    prev_base_weights = base_model.get_weights()\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    fcnn_model.set_weights(fcnn_weights)\n",
    "\n",
    "copy_weights(base_model=model, fcnn_model=fcnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_heatmap(images, heatmap, n_cols=5, n_rows=1):\n",
    "    \"\"\"Visualize heatmap\"\"\"\n",
    "    figure(figsize=(3 * n_cols, 2 * 3 * n_rows))\n",
    "    for n,i in enumerate(np.arange(n_cols * n_rows)): #np.random.randint(len(heatmap), size = n_cols*n_rows)):\n",
    "        plt.subplot(2 * n_rows, n_cols, n + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i])\n",
    "\n",
    "        plt.subplot(2 * n_rows, n_cols, n + 1 + n_cols)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(heatmap[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fcnn_model.predict(np.array(val_images))\n",
    "visualize_heatmap(val_images, predictions[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detection\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "def get_bboxes_and_decision_function(fcnn_model, images, image_shapes):\n",
    "    cropped_images = np.array([transform.resize(image, IMAGE_SHAPE, mode=\"reflect\") for image in images])\n",
    "    pred_bboxes, decision_function = [], []\n",
    "\n",
    "    # Predict\n",
    "    predictions = fcnn_model.predict(cropped_images)\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    return pred_bboxes, decision_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "\n",
    "def show_bboxes(bboxes, ax, color=\"black\", text=None):\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        ax.add_patch(patches.Rectangle((bbox[1], bbox[0]), bbox[3] - bbox[1], bbox[2] - bbox[0], fill=False, color=color))\n",
    "        if text is not None:\n",
    "            ax.text(bbox[1], bbox[0], text[i], color=color)\n",
    "\n",
    "def visualize_bboxes(images, pred_bboxes, true_bboxes=None, decision_function=None, n_cols=5, n_rows=1):\n",
    "    figure(figsize = (3*n_cols,3*n_rows))\n",
    "    pred_bboxes = np.array(pred_bboxes, dtype=np.int32)\n",
    "    if true_bboxes is not None:\n",
    "        true_bboxes = np.array(true_bboxes, dtype=np.int32)\n",
    "\n",
    "    for n,i in enumerate(np.random.choice(range(len(images)), size=n_cols * n_rows, replace=False)):\n",
    "        ax = plt.subplot(n_rows,n_cols,n+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i])\n",
    "        _text = ([\"{0:0.2f}\".format(decision_function[prec]) for prec in np.where(pred_bboxes[:, 0] == i)[0]]\n",
    "                 if decision_function is not None else None)\n",
    "\n",
    "        show_bboxes(bboxes=pred_bboxes[pred_bboxes[:, 0] == i, 1:], ax=ax, color=\"blue\", text=_text)\n",
    "\n",
    "        if true_bboxes is not None:\n",
    "            show_bboxes(bboxes=true_bboxes[true_bboxes[:, 0] == i, 1:], ax=ax, color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=val_images, image_shapes=val_shapes)\n",
    "\n",
    "visualize_bboxes(images=val_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=val_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scores import best_match, average_precision\n",
    "\n",
    "def precision_recall_curve(pred_bboxes, true_bboxes, decision_function):\n",
    "    precision, recall = [], []\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "def show_precision_recall(pred_bboxes, true_bboxes, decision_function):\n",
    "    precision, recall = precision_recall_curve(pred_bboxes=pred_bboxes, true_bboxes=true_bboxes, decision_function=decision_function)\n",
    "    ap = average_precision(precision=precision, recall=recall)\n",
    "\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "\n",
    "    plt.plot(recall, precision)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.xticks(np.arange(0, 1.05, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.05, 0.1))\n",
    "    plt.grid(color=\"white\")\n",
    "    plt.title('Precision-Recall curve: AP={0:0.2f}'.format(ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_precision_recall(pred_bboxes=pred_bboxes, true_bboxes=val_bboxes, decision_function=decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold\n",
    "\n",
    "Select threshold for `recall=0.6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 3.11776\n",
    "\n",
    "def detect(fcnn_model, images, image_shapes, threshold=THRESHOLD, return_decision=True):\n",
    "    \"\"\"Get bboxes with decision_function not less then threshold.\"\"\"\n",
    "    pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model, images, image_shapes)\n",
    "    result, result_decision = [], []\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    if return_decision:\n",
    "        return result, result_decision\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bboxes, decision_function = detect(fcnn_model=fcnn_model, images=val_images, image_shapes=val_shapes, return_decision=True)\n",
    "\n",
    "visualize_bboxes(images=val_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=val_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )\n",
    "\n",
    "show_precision_recall(pred_bboxes=pred_bboxes, true_bboxes=val_bboxes, decision_function=decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_bboxes, test_shapes = load_dataset(\"test\")\n",
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=test_images, image_shapes=test_shapes)\n",
    "visualize_bboxes(images=test_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=test_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )\n",
    "\n",
    "show_precision_recall(pred_bboxes=pred_bboxes, true_bboxes=test_bboxes, decision_function=decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard negative mining (optional)\n",
    "\n",
    "You can upgrade the score with hard negative mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hard_negative(train_images, image_shapes, train_bboxes, X_val, Y_val, base_model, fcnn_model):\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_negative(train_images=train_images, image_shapes=train_shapes, train_bboxes=train_bboxes, X_val=X_val, Y_val=Y_val, base_model=model, fcnn_model=fcnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(...)\n",
    "copy_weights(base_model=model, fcnn_model=fcnn_model)\n",
    "\n",
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=val_images, image_shapes=val_shapes)\n",
    "\n",
    "visualize_bboxes(images=val_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=val_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )\n",
    "\n",
    "show_precision_recall(pred_bboxes=pred_bboxes, true_bboxes=val_bboxes, decision_function=decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real image dataset\n",
    "\n",
    "Now we can test our algorithm on original (not scaled) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images, original_bboxes, original_shapes = load_dataset(\"original\")\n",
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=original_images, image_shapes=original_shapes)\n",
    "visualize_bboxes(images=original_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=original_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )\n",
    "\n",
    "show_precision_recall(pred_bboxes=pred_bboxes, true_bboxes=original_bboxes, decision_function=decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multi scale detector (optional)\n",
    "\n",
    "Write and test detector with pyramid representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiscale_detector(fcnn_model, images, image_shapes):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next  step\n",
    "\n",
    "Next steps in deep learning detection are R-CNN, Faster R-CNN and SSD architectures.\n",
    "This architecture realization is quite complex.\n",
    "For this reason the task doesn't cover them, but you can find the articles in the internet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
