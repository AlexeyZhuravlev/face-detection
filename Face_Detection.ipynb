{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "\n",
    "Hello! In this task you will create your own deep face detector.\n",
    "\n",
    "First of all, we need import some usefull stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_data import load_dataset, unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load dataset.\n",
    "\n",
    "Each image in train, validation and test datasets have shape (176, 176, 3), but part of this image is black background. Interesting image aligned at top left corner.\n",
    "\n",
    "Bounding boxes define face in image and consist of 7 integer numbers: [image_index, min_row, min_col, max_row, max_col]. Bounding box width and height are 32 +/- 8 pixels wide.\n",
    "\n",
    "`train_bboxes` and `val_bboxes` is a list of bboxes.\n",
    "\n",
    "`train_shapes` and `val_shapes` is a list of interesting image shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First run will download 30 MB data from github\n",
    "\n",
    "train_images, train_bboxes, train_shapes = load_dataset(\"train\")\n",
    "val_images, val_bboxes, val_shapes = load_dataset(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "For learning we should extract positive and negative samples from image.\n",
    "Positive and negative samples counts should be similar.\n",
    "Every samples should have same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_SHAPE = (32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scores import iou_score\n",
    "\n",
    "def is_new_bbox(new_bbox, true_bboxes, eps=1e-1):\n",
    "    \"\"\"There bbox is 4 ints [min_row, min_col, max_row, max_col] without image index.\"\"\"\n",
    "    for bbox in true_bboxes:\n",
    "        if iou_score(new_bbox, bbox) >= eps:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_positive_negative(images, true_bboxes, image_shapes):\n",
    "    \"\"\"Retrieve positive and negative samples from image.\"\"\"\n",
    "    positive = []\n",
    "    negative = []\n",
    "    \n",
    "    # Write code here\n",
    "   \n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samples(images, true_bboxes, image_shapes):\n",
    "    \"\"\"Usefull samples for learning.\n",
    "    \n",
    "    X - positive and negative samples.\n",
    "    Y - one hot encoded list of zeros and ones. One is positive marker.\n",
    "    \"\"\"\n",
    "    positive, negative = get_positive_negative(images=images, true_bboxes=true_bboxes, \n",
    "                                               image_shapes=image_shapes)\n",
    "    X = positive\n",
    "    Y = [[0, 1]] * len(positive)\n",
    "    \n",
    "    X.extend(negative)\n",
    "    Y.extend([[1, 0]] * len(negative))\n",
    "    \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_samples(data, n_cols=5, n_rows=1):\n",
    "    \"\"\"Visualize samples.\"\"\"\n",
    "    figure(figsize = (3*n_cols,3*n_rows))\n",
    "    for n,i in enumerate(np.random.randint(len(data), size = n_cols*n_rows)):\n",
    "        plt.subplot(n_rows,n_cols,n+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(data[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_samples(train_images, train_bboxes, train_shapes)\n",
    "X_val, Y_val = get_samples(val_images, val_bboxes, val_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There we should see faces\n",
    "print(Y_train.shape)\n",
    "visualize_samples(X_train[Y_train[:, 1] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There we shouldn't see faces\n",
    "visualize_samples(X_train[Y_train[:, 1] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificator training\n",
    "\n",
    "First of all, we should train face classifier that checks if face represented on sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator # Usefull thing. Read the doc.\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                            )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "# Very usefull, pay attention\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "from graph import plot_history\n",
    "\n",
    "def fit(model_name, model, datagen, X_train, Y_train, X_val, Y_val, class_weight=None, epochs=10, lr=0.001, verbose=False):\n",
    "    \"\"\"Fit model.\n",
    "    \n",
    "    You can edit this function anyhow.\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "\n",
    "    model.compile(optimizer=RMSprop(lr=lr), # You can use another optimizer\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
    "                                  validation_data=(datagen.standardize(X_val), Y_val),\n",
    "                                  epochs=epochs, steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "                                  callbacks=[ModelCheckpoint(\"data/checkpoints/{model_name}\".format(model_name=model_name) + \"-{epoch:02d}-{val_loss:.2f}.hdf5\", save_best_only=True),\n",
    "                                            ],\n",
    "                                  class_weight=class_weight,\n",
    "                                 )  # start training\n",
    "    \n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Input, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "# Classification model\n",
    "# You can start from LeNet architecture\n",
    "\n",
    "x = inputs = Input(shape=SAMPLE_SHAPE)\n",
    "\n",
    "# Write code here\n",
    "\n",
    "# This creates a model\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "fit(model_name=\"MODEL_NAME\", model=model, datagen=datagen, X_train=X_train, X_val=X_val, Y_train=Y_train, Y_val=Y_val, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning model weights saves in folder `data/checkpoints/`.\n",
    "Use `model.load_weights(fname)` to load best weights from learning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection\n",
    "\n",
    "If you have selected classification architecture with high validation score, you can use this architecture for detection.\n",
    "\n",
    "Convert classification architecture to fully convolutional neural network (FCNN), that returns heatmap of activation.\n",
    "\n",
    "You should replace fully-connected layers with convolutional layers. Then you need write function that replace fcnn weights with base model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FCNN\n",
    "\n",
    "IMAGE_SHAPE = (176, 176, 3)\n",
    "\n",
    "def generate_fcnn_model(image_shape):\n",
    "    \"\"\"After model compilation image size fixes.\n",
    "    \n",
    "    So, we need create a function to change size later.\n",
    "    \"\"\"\n",
    "    x = inputs = Input(shape=image_shape)\n",
    "\n",
    "    # Write code there\n",
    "\n",
    "    # This creates a model\n",
    "    predictions = Conv2D(1, (1, 1), activation='relu')(x)\n",
    "    return Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "fcnn_model = generate_fcnn_model(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_weights(base_model, fcnn_model):\n",
    "    \"\"\"Set FCNN weights from base model.\n",
    "    \"\"\"\n",
    "    \n",
    "    fcnn_weights = []\n",
    "    prev_fcnn_weights = fcnn_model.get_weights()\n",
    "    prev_base_weights = base_model.get_weights()\n",
    "    \n",
    "    # Write code there\n",
    "        \n",
    "    fcnn_model.set_weights(fcnn_weights)\n",
    "\n",
    "copy_weights(base_model=model, fcnn_model=fcnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graph import visualize_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fcnn_model.predict(np.array(val_images))\n",
    "visualize_heatmap(val_images, predictions[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector\n",
    "\n",
    "First detector part is getting bboxes and decision function.\n",
    "Greater decision function indicates better detector confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detection\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "def get_bboxes_and_decision_function(fcnn_model, images, image_shapes):\n",
    "    cropped_images = np.array([transform.resize(image, IMAGE_SHAPE, mode=\"reflect\") for image in images])\n",
    "    pred_bboxes, decision_function = [], []\n",
    "   \n",
    "    # Predict\n",
    "    predictions = fcnn_model.predict(cropped_images)\n",
    "\n",
    "    # Write code here\n",
    "        \n",
    "    return pred_bboxes, decision_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graph import visualize_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=val_images, image_shapes=val_shapes)\n",
    "\n",
    "visualize_bboxes(images=val_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=val_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scores import best_match\n",
    "from graph import plot_precision_recall\n",
    "\n",
    "def precision_recall_curve(pred_bboxes, true_bboxes, decision_function):\n",
    "    precision, recall = [], []\n",
    "    \n",
    "    # Write code here\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_curve(pred_bboxes=pred_bboxes, true_bboxes=val_bboxes, decision_function=decision_function)\n",
    "plot_precision_recall(precision=precision, recall=recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold\n",
    "\n",
    "Next step in detector creating is select threshold for decision_function.\n",
    "Every possible threshold presents point on recall-precision graph.\n",
    "\n",
    "Select threshold for `recall=0.85`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = ...\n",
    "\n",
    "def detect(fcnn_model, images, image_shapes, threshold=THRESHOLD, return_decision=True):\n",
    "    \"\"\"Get bboxes with decision_function not less then threshold.\"\"\"\n",
    "    pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model, images, image_shapes)   \n",
    "    result, result_decision = [], []\n",
    "    \n",
    "    # Write code here\n",
    "\n",
    "    if return_decision:\n",
    "        return result, result_decision\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bboxes, decision_function = detect(fcnn_model=fcnn_model, images=val_images, image_shapes=val_shapes, return_decision=True)\n",
    "\n",
    "visualize_bboxes(images=val_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=val_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )\n",
    "\n",
    "precision, recall = precision_recall_curve(pred_bboxes=pred_bboxes, true_bboxes=val_bboxes, decision_function=decision_function)\n",
    "plot_precision_recall(precision=precision, recall=recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset\n",
    "\n",
    "Last detector preparation step is testing.\n",
    "\n",
    "Attention: to avoid overfitting, after testing algorithm you should run `./prepare_data.ipynb`, and start all fitting from beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_bboxes, test_shapes = load_dataset(\"test\")\n",
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=test_images, image_shapes=test_shapes)\n",
    "\n",
    "# Write code here: Visualize bboxes and plot precision-recall curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real image dataset\n",
    "\n",
    "Test your algorithm on original (not scaled) data.\n",
    "Visualize bboxes and plot precision-recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First run will download 523 MB data from github\n",
    "\n",
    "original_images, original_bboxes, original_shapes = load_dataset(\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard negative mining (optional)\n",
    "\n",
    "Upgrade the score with hard negative mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative(train_images, image_shapes, train_bboxes, X_val, Y_val, base_model, fcnn_model):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_negative(train_images=train_images, image_shapes=train_shapes, train_bboxes=train_bboxes, X_val=X_val, Y_val=Y_val, base_model=model, fcnn_model=fcnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_weights(base_model=model, fcnn_model=fcnn_model)\n",
    "\n",
    "pred_bboxes, decision_function = get_bboxes_and_decision_function(fcnn_model=fcnn_model, images=val_images, image_shapes=val_shapes)\n",
    "\n",
    "visualize_bboxes(images=val_images,\n",
    "                 pred_bboxes=pred_bboxes,\n",
    "                 true_bboxes=val_bboxes,\n",
    "                 decision_function=decision_function\n",
    "                )\n",
    "\n",
    "plot_precision_recall(pred_bboxes=pred_bboxes, true_bboxes=val_bboxes, decision_function=decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Multi scale detector (optional)\n",
    "\n",
    "Write and test detector with pyramid representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiscale_detector(fcnn_model, images, image_shapes):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Next  step\n",
    "\n",
    "Next steps in deep learning detection are R-CNN, Faster R-CNN and SSD architectures.\n",
    "This architecture realization is quite complex.\n",
    "For this reason the task doesn't cover them, but you can find the articles in the internet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
